{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AZXuAaBzE9zv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'sudo' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "ERROR: Invalid requirement: \"'imageio==2.4.0'\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyvirtualdisplay\n",
      "  Downloading PyVirtualDisplay-2.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting EasyProcess\n",
      "  Downloading EasyProcess-0.3-py2.py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: EasyProcess, pyvirtualdisplay\n",
      "Successfully installed EasyProcess-0.3 pyvirtualdisplay-2.0\n",
      "Collecting tf-agents\n",
      "  Downloading tf_agents-0.7.1-py3-none-any.whl (1.2 MB)\n",
      "Collecting gym>=0.17.0\n",
      "  Downloading gym-0.18.0.tar.gz (1.6 MB)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-agents) (1.6.0)\n",
      "Collecting tensorflow-probability>=0.12.1\n",
      "  Downloading tensorflow_probability-0.12.1-py2.py3-none-any.whl (4.8 MB)\n",
      "Requirement already satisfied: pillow>=7.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-agents) (8.0.1)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-agents) (1.12.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n",
      "\n",
      "We recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n",
      "\n",
      "gym 0.18.0 requires Pillow<=7.2.0, but you'll have pillow 8.0.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: protobuf>=3.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-agents) (3.14.0)\n",
      "Collecting gin-config>=0.4.0\n",
      "  Downloading gin_config-0.4.0-py2.py3-none-any.whl (46 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-agents) (3.7.4.3)\n",
      "Requirement already satisfied: absl-py>=0.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-agents) (0.11.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-agents) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tf-agents) (1.19.2)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from gym>=0.17.0->tf-agents) (1.5.2)\n",
      "Collecting pyglet<=1.5.0,>=1.4.0\n",
      "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.5-cp38-cp38-win_amd64.whl (83 kB)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.12.1->tf-agents) (4.4.2)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-probability>=0.12.1->tf-agents) (0.3.3)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym>=0.17.0->tf-agents) (0.18.2)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (setup.py): started\n",
      "  Building wheel for gym (setup.py): finished with status 'done'\n",
      "  Created wheel for gym: filename=gym-0.18.0-py3-none-any.whl size=1656451 sha256=1d9894504193019895e582e32431ee69da8b7eb1e32c313449599b44e84d3ded\n",
      "  Stored in directory: c:\\users\\captain\\appdata\\local\\pip\\cache\\wheels\\d8\\e7\\68\\a3f0f1b5831c9321d7523f6fd4e0d3f83f2705a1cbd5daaa79\n",
      "Successfully built gym\n",
      "Installing collected packages: pyglet, gym, dm-tree, tensorflow-probability, gin-config, tf-agents\n",
      "Successfully installed dm-tree-0.1.5 gin-config-0.4.0 gym-0.18.0 pyglet-1.5.0 tensorflow-probability-0.12.1 tf-agents-0.7.1\n"
     ]
    }
   ],
   "source": [
    "!sudo apt-get install -y xvfb ffmpeg\n",
    "!pip install 'imageio==2.4.0'\n",
    "!pip install pyvirtualdisplay\n",
    "!pip install tf-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RKa7BaiTGESw"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import pyvirtualdisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.reinforce import reinforce_agent\n",
    "\n",
    "from tf_agents.drivers import dynamic_step_driver\n",
    "\n",
    "from tf_agents.environments import suite_gym\n",
    "\n",
    "from tf_agents.environments import tf_py_environment\n",
    "\n",
    "from tf_agents.eval import metric_utils\n",
    "\n",
    "from tf_agents.metrics import tf_metrics\n",
    "\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "\n",
    "from tf_agents.trajectories import trajectory\n",
    "\n",
    "from tf_agents.utils import common\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "\n",
    "# set up virtual display\n",
    "display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5IlxOO8K6cH"
   },
   "outputs": [],
   "source": [
    "env_name = \"CartPole-v0\" # @param {type:\"string\"}\n",
    "num_iterations = 250 # @param {type:\"integer\"}\n",
    "collect_episodes_per_iteration = 2 # @param {type:\"integer\"}\n",
    "replay_buffer_capasity = 2000 # @param {type:\"integer\"}\n",
    "\n",
    "fc_layer_params = (100,)\n",
    "\n",
    "learning_rate = 1e-3 # @param {type:\"number\"}\n",
    "log_interval = 25 # @param {type:\"integer\"}\n",
    "num_eval_episodes = 10 # @param {type:\"integer\"}\n",
    "eval_interval = 50 # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EHk1vosEMqBg"
   },
   "outputs": [],
   "source": [
    "env = suite_gym.load(env_name)\n",
    "print(\"Load the artpole enviroment successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aPLIcYNdM8ZG"
   },
   "outputs": [],
   "source": [
    "print('Observation Spec:')\n",
    "print(env.time_step_spec().observation)\n",
    "print('Action Spec:')\n",
    "print(env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcL-DJtpNWVY"
   },
   "outputs": [],
   "source": [
    "train_py_env = suite_gym.load(env_name)\n",
    "eval_py_env = suite_gym.load(env_name)\n",
    "\n",
    "train_env = tf_py_environment.TFPyEnvironment(train_py_env)\n",
    "eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\n",
    "\n",
    "print(\"Created the enviroment successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "36DWgQ5ZQd5k"
   },
   "outputs": [],
   "source": [
    "actor_net = actor_distribution_network.ActorDistributionNetwork(\n",
    "    train_env.observation_spec(),\n",
    "    train_env.action_spec(),\n",
    "    fc_layer_params=fc_layer_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WAvx2PQVTaSB"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.compat.v1.train.AdadeltaOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "train_step_counter = tf.compat.v2.Variable(0)\n",
    "\n",
    "tf_agent = reinforce_agent.ReinforceAgent(\n",
    "    train_env.time_step_spec(),\n",
    "    train_env.action_spec(),\n",
    "    actor_network=actor_net,\n",
    "    optimizer=optimizer,\n",
    "    normalize_returns = True,\n",
    "    train_step_counter=train_step_counter)\n",
    "tf_agent.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8wao1iC4VCC0"
   },
   "outputs": [],
   "source": [
    "eval_policy = tf_agent.policy\n",
    "collect_policy = tf_agent.collect_policy\n",
    "print(\"Created policies successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6Y5uMBSVVfB"
   },
   "outputs": [],
   "source": [
    "def compute_avg_return(environment, policy, num_episodes=10):\n",
    "\n",
    "  total_return = 0.0\n",
    "  for _ in range(num_episodes):\n",
    "\n",
    "    time_step = environment.reset()\n",
    "    episode_return = 0.0\n",
    "\n",
    "    while not time_step.is_last():\n",
    "      action_step = policy.action(time_step)\n",
    "      time_step = environment.step(action_step.action)\n",
    "      episode_return += time_step.reward\n",
    "    total_return += episode_return\n",
    "\n",
    "  avg_return = total_return / num_eval_episodes\n",
    "  return avg_return.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cwfQ0_wtXKYj"
   },
   "outputs": [],
   "source": [
    "replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\n",
    "    data_spec=tf_agent.collect_data_spec,\n",
    "    batch_size=train_env.batch_size,\n",
    "    max_length=replay_buffer_capasity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WZcp5yvqXmbo"
   },
   "outputs": [],
   "source": [
    "def collect_episode(environment, policy, num_episodes):\n",
    "\n",
    "  episode_counter = 0\n",
    "  environment.reset()\n",
    "\n",
    "  while episode_counter < num_eval_episodes:\n",
    "    time_step = environment.current_time_step()\n",
    "    action_step = policy.action(time_step)\n",
    "    next_time_step = environment.step(action_step.action)\n",
    "    traj = trajectory.from_transition(time_step, action_step, next_time_step)\n",
    "\n",
    "    replay_buffer.add_batch(traj)\n",
    "\n",
    "    if traj.is_boundary():\n",
    "      episode_counter += 1\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4MNaQ9t6Ywxj"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "tf_agent.train = common.function(tf_agent.train)\n",
    "\n",
    "tf_agent.train_step_counter.assign(0)\n",
    "\n",
    "avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "\n",
    "  collect_episode(\n",
    "      train_env, tf_agent.collect_policy, collect_episodes_per_iteration)\n",
    "  \n",
    "  experience = replay_buffer.gather_all()\n",
    "  train_loss = tf_agent.train(experience)\n",
    "  replay_buffer.clear()\n",
    "\n",
    "  step = tf_agent.train_step_counter.numpy()\n",
    "\n",
    "  if step % log_interval == 0:\n",
    "    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\n",
    "\n",
    "  if step % eval_interval == 0:\n",
    "    avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\n",
    "    print('step = {0}: Average Return = {1}'.format(step, avg_return))\n",
    "    returns.append(avg_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V1Ip9qnBm7Ri"
   },
   "outputs": [],
   "source": [
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim(top=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAWax618oA-Y"
   },
   "outputs": [],
   "source": [
    "def embed_mp4(filename):\n",
    "  video = open(filename, 'rb').read()\n",
    "  b64 = base64.b64encode(video)\n",
    "  tag='''\n",
    "  <video width=\"640\" height=\"480\" controls>\n",
    "    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
    "  Your browser does not support the video tag.\n",
    "  </video>'''.format(b64.decode())\n",
    "\n",
    "  return IPython.display.HTML(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gpOkzXbwpn1J"
   },
   "outputs": [],
   "source": [
    "num_episodes = 3\n",
    "video_filename = 'imageio.mp4'\n",
    "with imageio.get_writer(video_filename, fps=60) as video:\n",
    "  for _ in range(num_episodes):\n",
    "    time_step = eval_env.reset()\n",
    "    video.append_data(eval_py_env.render())\n",
    "    while not time_step.is_last():\n",
    "      action_step = tf_agent.policy.action(time_step)\n",
    "      time_step = eval_env.step(action_step.action)\n",
    "      video.append_data(eval_py_env.render())\n",
    "\n",
    "embed_mp4(video_filename)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNmv40SunA6mgndsTkb5rDE",
   "name": "Reinforcement_learning.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
