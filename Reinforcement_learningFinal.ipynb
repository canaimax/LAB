{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Reinforcement_learningFinal.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNmv40SunA6mgndsTkb5rDE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"AZXuAaBzE9zv"},"source":["!sudo apt-get install -y xvfb ffmpeg\r\n","!pip install 'imageio==2.4.0'\r\n","!pip install pyvirtualdisplay\r\n","!pip install tf-agents"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RKa7BaiTGESw"},"source":["from __future__ import absolute_import\r\n","from __future__ import division\r\n","from __future__ import print_function\r\n","\r\n","import base64\r\n","import imageio\r\n","import IPython\r\n","import matplotlib\r\n","import matplotlib.pyplot as plt\r\n","import numpy as np\r\n","import PIL.Image\r\n","import pyvirtualdisplay\r\n","\r\n","import tensorflow as tf\r\n","\r\n","from tf_agents.agents.reinforce import reinforce_agent\r\n","\r\n","from tf_agents.drivers import dynamic_step_driver\r\n","\r\n","from tf_agents.environments import suite_gym\r\n","\r\n","from tf_agents.environments import tf_py_environment\r\n","\r\n","from tf_agents.eval import metric_utils\r\n","\r\n","from tf_agents.metrics import tf_metrics\r\n","\r\n","from tf_agents.networks import actor_distribution_network\r\n","\r\n","from tf_agents.replay_buffers import tf_uniform_replay_buffer\r\n","\r\n","from tf_agents.trajectories import trajectory\r\n","\r\n","from tf_agents.utils import common\r\n","\r\n","tf.compat.v1.enable_v2_behavior()\r\n","\r\n","# set up virtual display\r\n","display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\r\n","\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O5IlxOO8K6cH"},"source":["env_name = \"CartPole-v0\" # @param {type:\"string\"}\r\n","num_iterations = 250 # @param {type:\"integer\"}\r\n","collect_episodes_per_iteration = 2 # @param {type:\"integer\"}\r\n","replay_buffer_capasity = 2000 # @param {type:\"integer\"}\r\n","\r\n","fc_layer_params = (100,)\r\n","\r\n","learning_rate = 1e-3 # @param {type:\"number\"}\r\n","log_interval = 25 # @param {type:\"integer\"}\r\n","num_eval_episodes = 10 # @param {type:\"integer\"}\r\n","eval_interval = 50 # @param {type:\"integer\"}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EHk1vosEMqBg"},"source":["env = suite_gym.load(env_name)\r\n","print(\"Load the artpole enviroment successfully!\")\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aPLIcYNdM8ZG"},"source":["print('Observation Spec:')\r\n","print(env.time_step_spec().observation)\r\n","print('Action Spec:')\r\n","print(env.action_spec())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jcL-DJtpNWVY"},"source":["train_py_env = suite_gym.load(env_name)\r\n","eval_py_env = suite_gym.load(env_name)\r\n","\r\n","train_env = tf_py_environment.TFPyEnvironment(train_py_env)\r\n","eval_env = tf_py_environment.TFPyEnvironment(eval_py_env)\r\n","\r\n","print(\"Created the enviroment successfully!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"36DWgQ5ZQd5k"},"source":["actor_net = actor_distribution_network.ActorDistributionNetwork(\r\n","    train_env.observation_spec(),\r\n","    train_env.action_spec(),\r\n","    fc_layer_params=fc_layer_params)\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WAvx2PQVTaSB"},"source":["optimizer = tf.compat.v1.train.AdadeltaOptimizer(learning_rate=learning_rate)\r\n","\r\n","train_step_counter = tf.compat.v2.Variable(0)\r\n","\r\n","tf_agent = reinforce_agent.ReinforceAgent(\r\n","    train_env.time_step_spec(),\r\n","    train_env.action_spec(),\r\n","    actor_network=actor_net,\r\n","    optimizer=optimizer,\r\n","    normalize_returns = True,\r\n","    train_step_counter=train_step_counter)\r\n","tf_agent.initialize()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8wao1iC4VCC0"},"source":["eval_policy = tf_agent.policy\r\n","collect_policy = tf_agent.collect_policy\r\n","print(\"Created policies successfully!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E6Y5uMBSVVfB"},"source":["def compute_avg_return(environment, policy, num_episodes=10):\r\n","\r\n","  total_return = 0.0\r\n","  for _ in range(num_episodes):\r\n","\r\n","    time_step = environment.reset()\r\n","    episode_return = 0.0\r\n","\r\n","    while not time_step.is_last():\r\n","      action_step = policy.action(time_step)\r\n","      time_step = environment.step(action_step.action)\r\n","      episode_return += time_step.reward\r\n","    total_return += episode_return\r\n","\r\n","  avg_return = total_return / num_eval_episodes\r\n","  return avg_return.numpy()[0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cwfQ0_wtXKYj"},"source":["replay_buffer = tf_uniform_replay_buffer.TFUniformReplayBuffer(\r\n","    data_spec=tf_agent.collect_data_spec,\r\n","    batch_size=train_env.batch_size,\r\n","    max_length=replay_buffer_capasity)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WZcp5yvqXmbo"},"source":["def collect_episode(environment, policy, num_episodes):\r\n","\r\n","  episode_counter = 0\r\n","  environment.reset()\r\n","\r\n","  while episode_counter < num_eval_episodes:\r\n","    time_step = environment.current_time_step()\r\n","    action_step = policy.action(time_step)\r\n","    next_time_step = environment.step(action_step.action)\r\n","    traj = trajectory.from_transition(time_step, action_step, next_time_step)\r\n","\r\n","    replay_buffer.add_batch(traj)\r\n","\r\n","    if traj.is_boundary():\r\n","      episode_counter += 1\r\n","\r\n","      "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4MNaQ9t6Ywxj"},"source":["try:\r\n","  %%time\r\n","except:\r\n","  pass\r\n","\r\n","tf_agent.train = common.function(tf_agent.train)\r\n","\r\n","tf_agent.train_step_counter.assign(0)\r\n","\r\n","avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\r\n","returns = [avg_return]\r\n","\r\n","for _ in range(num_iterations):\r\n","\r\n","  collect_episode(\r\n","      train_env, tf_agent.collect_policy, collect_episodes_per_iteration)\r\n","  \r\n","  experience = replay_buffer.gather_all()\r\n","  train_loss = tf_agent.train(experience)\r\n","  replay_buffer.clear()\r\n","\r\n","  step = tf_agent.train_step_counter.numpy()\r\n","\r\n","  if step % log_interval == 0:\r\n","    print('step = {0}: loss = {1}'.format(step, train_loss.loss))\r\n","\r\n","  if step % eval_interval == 0:\r\n","    avg_return = compute_avg_return(eval_env, tf_agent.policy, num_eval_episodes)\r\n","    print('step = {0}: Average Return = {1}'.format(step, avg_return))\r\n","    returns.append(avg_return)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"V1Ip9qnBm7Ri"},"source":["steps = range(0, num_iterations + 1, eval_interval)\r\n","plt.plot(steps, returns)\r\n","plt.ylabel('Average Return')\r\n","plt.xlabel('Step')\r\n","plt.ylim(top=250)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wAWax618oA-Y"},"source":["def embed_mp4(filename):\r\n","  video = open(filename, 'rb').read()\r\n","  b64 = base64.b64encode(video)\r\n","  tag='''\r\n","  <video width=\"640\" height=\"480\" controls>\r\n","    <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\r\n","  Your browser does not support the video tag.\r\n","  </video>'''.format(b64.decode())\r\n","\r\n","  return IPython.display.HTML(tag)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpOkzXbwpn1J"},"source":["num_episodes = 3\r\n","video_filename = 'imageio.mp4'\r\n","with imageio.get_writer(video_filename, fps=60) as video:\r\n","  for _ in range(num_episodes):\r\n","    time_step = eval_env.reset()\r\n","    video.append_data(eval_py_env.render())\r\n","    while not time_step.is_last():\r\n","      action_step = tf_agent.policy.action(time_step)\r\n","      time_step = eval_env.step(action_step.action)\r\n","      video.append_data(eval_py_env.render())\r\n","\r\n","embed_mp4(video_filename)\r\n"],"execution_count":null,"outputs":[]}]}