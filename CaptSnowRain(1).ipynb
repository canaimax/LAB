{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CaptSnowRain.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyp0NPwgE6yT"
      },
      "source": [
        "# Snow & Rain CNN\n",
        "###     \n",
        "###  Captain\n",
        "### Snow Rain train model, validation and overfitting\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_PB-coP5YWo"
      },
      "source": [
        "## PREPARE\n",
        "####          \n",
        "#### Train Snow Images:  1200\n",
        "#### Train Rain Images:  1200\n",
        "####  Test Snow Images:   500\n",
        "####  Test Rain Images:   500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gp0PHuSsE6yt"
      },
      "source": [
        "### IMPORT LIBRARIES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoEgbjsZRM4F"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "os.getcwd()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4NOgqcD50m2"
      },
      "source": [
        "### DRIVE  DIRs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uJ6jZbOqTov"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhH9Lq5MF9af"
      },
      "source": [
        "\r\n",
        "# For some reason Colab was crashing, so I delegated the data\r\n",
        "\r\n",
        "\r\n",
        "train_dir_m = \"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/train\"\r\n",
        "test_dir_m = \"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/test\"\r\n",
        "\r\n",
        "train_dir_predict = \"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/train\"\r\n",
        "test_dir_predict = \"content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/test\"\r\n",
        "\r\n",
        "test_dir=\"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN\"\r\n",
        "train_dir=\"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN\"\r\n",
        "\r\n",
        "\r\n",
        "train_dir_snow=(\"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/train/snowtr\")\r\n",
        "train_snow_fnames = os.listdir( train_dir_snow )\r\n",
        "print(train_snow_fnames[:5])\r\n",
        "\r\n",
        "train_dir_rain=(\"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/train/raintr\")\r\n",
        "train_rain_fnames = os.listdir( train_dir_rain)\r\n",
        "print(train_rain_fnames[:5])\r\n",
        "\r\n",
        "test_dir_snowT=(\"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/test/snowte\")\r\n",
        "test_snowT_fnames = os.listdir( test_dir_snowT )\r\n",
        "print(test_snowT_fnames[:5])\r\n",
        "\r\n",
        "test_dir_rainT=(\"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/test/rainte\")\r\n",
        "test_rainT_fnames = os.listdir( test_dir_rainT)\r\n",
        "print(test_rainT_fnames[:5])\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAJ7J_am-abX"
      },
      "source": [
        "## VISUALIZE SNOW & RAIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNLsPw-B6GJS"
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 4 X 4\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# index of images\n",
        "pic_index = 0 \n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols*4, nrows*4)\n",
        "\n",
        "pic_index+=4\n",
        "\n",
        "next_snow_pix = [os.path.join(train_dir_snow, fname) \n",
        "                for fname in train_snow_fnames[ pic_index-4:pic_index] \n",
        "               ]\n",
        "\n",
        "next_rain_pix = [os.path.join(train_dir_rain, fname) \n",
        "                for fname in train_rain_fnames[ pic_index-4:pic_index]\n",
        "               ]\n",
        "# off grids\n",
        "for i, img_path in enumerate(next_snow_pix+next_rain_pix):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') \n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tecO9V9ME6y7"
      },
      "source": [
        "## CREATING MODELS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCdXHsgxE6y9"
      },
      "source": [
        "### Add layers MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JIfibR6yE6y9"
      },
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "model = models.Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Csv1fvBVE6y9"
      },
      "source": [
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(layers.MaxPool2D(2, 2))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPool2D(2, 2))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPool2D(2, 2))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPool2D(2, 2))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(512, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJslG_AHE6y-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlQEfyohE6y-"
      },
      "source": [
        "####  Train model also use binary_crossentropy for loss and activate with sigmoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uSFqSnREE6y_"
      },
      "source": [
        "\n",
        "from keras import optimizers\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                optimizer=optimizers.RMSprop(lr=1e-4), \n",
        "                metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghEhntanE6zA"
      },
      "source": [
        "# Use ImageDataGenerator\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "\n",
        "# train\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir_m,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')\n",
        "\n",
        "# validate\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir_m,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=20,\n",
        "    class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1tDsndnE6zB"
      },
      "source": [
        "history = model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=10,\n",
        "    epochs=6,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3FVWo7d_S-i"
      },
      "source": [
        "###  ACCURACY and LOSS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG5RsL1P_V2h"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "accuracy=history.history[\"acc\"]\n",
        "loss=history.history['loss']\n",
        "val_accuracy=history.history['val_acc']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs=range(len(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BOT2ejp_pRd"
      },
      "source": [
        "plt.plot(epochs,accuracy)\n",
        "plt.plot(epochs,val_accuracy)\n",
        "plt.title(\"training and validation Accuracy\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yhm9rvM_AXEG"
      },
      "source": [
        "plt.plot(epochs,loss)\n",
        "plt.plot(epochs,val_loss)\n",
        "plt.title(\"training and Validation loss\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19fNbVr9E6zL"
      },
      "source": [
        "## PREDICTIONS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qleaeEtUE6zL"
      },
      "source": [
        "### IMAGE GENERATOR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Om2q11PCE6zM"
      },
      "source": [
        "\n",
        "\n",
        "Batch_size = 32\n",
        "image_shape = 150\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35JgtiHtE6zM"
      },
      "source": [
        "train_image_generator = ImageDataGenerator(\n",
        "    # image augmentation\n",
        "    rotation_range = 0.2,\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    horizontal_flip=True,\n",
        "    rescale = 1./255 #normalize the image \n",
        "             )\n",
        "test_image_generator = ImageDataGenerator(\n",
        "    rescale = 1./255\n",
        "             )\n",
        "\n",
        "\n",
        "train_image_gen = train_image_generator.flow_from_directory(\n",
        "batch_size = Batch_size,\n",
        "directory = train_dir_predict,\n",
        "shuffle = True,\n",
        "target_size = (image_shape,image_shape),\n",
        "class_mode= \"binary\")\n",
        "\n",
        "\n",
        "test_image_gen =test_image_generator.flow_from_directory(\n",
        "batch_size = Batch_size,\n",
        "directory = test_dir,\n",
        "shuffle = False,\n",
        "target_size = (image_shape,image_shape),\n",
        "class_mode= \"binary\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqoqg6wyE6zN"
      },
      "source": [
        "train_image_gen.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqRy2iJwE6zO"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\r\n",
        "image = load_img(\"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/18.jpg\", target_size=(image_shape, image_shape)) # load image and resize\r\n",
        "type(image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtqTBmwvE6zQ"
      },
      "source": [
        "img = img_to_array(image)\r\n",
        "type(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAMYzcyoE6zQ"
      },
      "source": [
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rTuNfm8E6zR"
      },
      "source": [
        "# Dimension & Normalize\r\n",
        "\r\n",
        "img = np.expand_dims(img, 0)\r\n",
        "img = img.astype(np.float32)/255.0\r\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bs3GnIIE6zR"
      },
      "source": [
        "### PREDICT MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H8rmGLwE6zS"
      },
      "source": [
        "model.predict(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V79hp1MrE6zS"
      },
      "source": [
        "img0 = load_img(\"/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/2.jpg\",target_size=(image_shape,image_shape))\n",
        "img0 = img_to_array(img0)\n",
        "img0 = np.expand_dims(img0,0)\n",
        "img0 = img0.astype(np.float32)/255.0\n",
        "model.predict(img0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg5GJyHVdJjD"
      },
      "source": [
        "### DEFs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMooHjzCE6zS"
      },
      "source": [
        "def load_images(folder):\n",
        "    outputs = []\n",
        "    for f in os.listdir(folder):\n",
        "        print(f)\n",
        "        img = load_img(os.path.join(folder, f),target_size=(image_shape,image_shape))\n",
        "        img = img_to_array(img)\n",
        "        img = np.expand_dims(img,0)\n",
        "        img = img.astype(np.float32)/255.0\n",
        "        outputs.append(img)\n",
        "    return np.concatenate(outputs)\n",
        "  \n",
        "\n",
        "def predict_classes(model, images, classes):\n",
        "    output = []\n",
        "    prediction = model.predict(images)\n",
        "\n",
        "    class_label = {value:key for key, value in classes.items()}\n",
        "    for p in prediction:\n",
        "        if p> 0.5:\n",
        "            output.append(class_label[1])\n",
        "        else:\n",
        "            output.append(class_label[0])\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVl_pnVgE6zT"
      },
      "source": [
        "###  PLOT IMAGE, Rain or Snow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epZ9Z_5fE6zT"
      },
      "source": [
        "# result predict\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.models import load_model\n",
        "img = load_img('/content/gdrive/MyDrive/Colab Notebooks/KTGCOLAB/SNOWRAIN/5.jpg', target_size=(150, 150))\n",
        "plt.imshow(img)\n",
        "img = img_to_array(img)\n",
        "img = img.reshape(1, 150, 150 , 3)\n",
        "img = img.astype('float32')\n",
        "result = model.predict(img)\n",
        "if(result==1):\n",
        "    print('Snow')\n",
        "else:\n",
        "    print(\"Rain\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}